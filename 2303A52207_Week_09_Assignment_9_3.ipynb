{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzG0AEC7PsiPpFsyeqGwzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhuparusha225/Gen-AI-2025/blob/main/2303A52207_Week_09_Assignment_9_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (1 ponto) Design a multilayer ANN architecture to identify the hand-written digits using the\n",
        "Keras deep learning library. Consider the MNIST data set\n",
        "\n",
        "2. (1 ponto) Calculate the accuracy with training and testing data\n",
        "\n",
        "3. (1 ponto) Also, change the architecture by tuning no. of hidden layers, no. of hidden neurons\n",
        "and activation functions in hidden layer. Identify best architecture in terms of testing accuracy\n",
        "\n",
        "          Tabela 1: ANN Architecture\n",
        "          Layer              Neurons       Activation Function\n",
        "          Hidden Layer - 1    128           swish\n",
        "          Hidden Layer - 2    128           swish\n",
        "          Hidden Layer - 3    128           swish\n",
        "\n",
        "          Tabela 2: Training Parameters\n",
        "          epochs   batch size     error metric     Optimizer\n",
        "          30           32            accuracy        adam\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "• Expected learning Outcomes from this assignment related to python\n",
        "\n",
        "– Students are able to build ANN model with python deep learning libraries to classify\n",
        "hand written digits\n",
        "\n",
        "– Students are able to measure training and testing performance of trained model"
      ],
      "metadata": {
        "id": "NU51McZQGWsr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdM8n4XBGT8f",
        "outputId": "fc3abf61-1d99-4397-9c8d-4ed00f77ae00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 - 12s - 6ms/step - accuracy: 0.9301 - loss: 0.2347 - val_accuracy: 0.9647 - val_loss: 0.1133\n",
            "Epoch 2/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9693 - loss: 0.0986 - val_accuracy: 0.9697 - val_loss: 0.0949\n",
            "Epoch 3/30\n",
            "1875/1875 - 11s - 6ms/step - accuracy: 0.9775 - loss: 0.0695 - val_accuracy: 0.9699 - val_loss: 0.0939\n",
            "Epoch 4/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9842 - loss: 0.0495 - val_accuracy: 0.9759 - val_loss: 0.0899\n",
            "Epoch 5/30\n",
            "1875/1875 - 10s - 5ms/step - accuracy: 0.9870 - loss: 0.0399 - val_accuracy: 0.9779 - val_loss: 0.0778\n",
            "Epoch 6/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9891 - loss: 0.0319 - val_accuracy: 0.9779 - val_loss: 0.0789\n",
            "Epoch 7/30\n",
            "1875/1875 - 11s - 6ms/step - accuracy: 0.9910 - loss: 0.0277 - val_accuracy: 0.9795 - val_loss: 0.0780\n",
            "Epoch 8/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9930 - loss: 0.0218 - val_accuracy: 0.9784 - val_loss: 0.0857\n",
            "Epoch 9/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9930 - loss: 0.0212 - val_accuracy: 0.9796 - val_loss: 0.0993\n",
            "Epoch 10/30\n",
            "1875/1875 - 9s - 5ms/step - accuracy: 0.9943 - loss: 0.0178 - val_accuracy: 0.9741 - val_loss: 0.1147\n",
            "Epoch 11/30\n",
            "1875/1875 - 10s - 5ms/step - accuracy: 0.9938 - loss: 0.0195 - val_accuracy: 0.9788 - val_loss: 0.0861\n",
            "Epoch 12/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.9766 - val_loss: 0.1083\n",
            "Epoch 13/30\n",
            "1875/1875 - 10s - 5ms/step - accuracy: 0.9954 - loss: 0.0145 - val_accuracy: 0.9745 - val_loss: 0.1436\n",
            "Epoch 14/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9952 - loss: 0.0155 - val_accuracy: 0.9803 - val_loss: 0.1003\n",
            "Epoch 15/30\n",
            "1875/1875 - 8s - 4ms/step - accuracy: 0.9953 - loss: 0.0151 - val_accuracy: 0.9781 - val_loss: 0.1084\n",
            "Epoch 16/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9962 - loss: 0.0120 - val_accuracy: 0.9798 - val_loss: 0.1078\n",
            "Epoch 17/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9964 - loss: 0.0131 - val_accuracy: 0.9806 - val_loss: 0.1131\n",
            "Epoch 18/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9964 - loss: 0.0118 - val_accuracy: 0.9816 - val_loss: 0.0989\n",
            "Epoch 19/30\n",
            "1875/1875 - 7s - 3ms/step - accuracy: 0.9962 - loss: 0.0137 - val_accuracy: 0.9794 - val_loss: 0.1162\n",
            "Epoch 20/30\n",
            "1875/1875 - 11s - 6ms/step - accuracy: 0.9969 - loss: 0.0098 - val_accuracy: 0.9777 - val_loss: 0.1501\n",
            "Epoch 21/30\n",
            "1875/1875 - 10s - 5ms/step - accuracy: 0.9962 - loss: 0.0131 - val_accuracy: 0.9760 - val_loss: 0.1409\n",
            "Epoch 22/30\n",
            "1875/1875 - 10s - 5ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 0.9798 - val_loss: 0.1143\n",
            "Epoch 23/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9971 - loss: 0.0100 - val_accuracy: 0.9765 - val_loss: 0.1409\n",
            "Epoch 24/30\n",
            "1875/1875 - 11s - 6ms/step - accuracy: 0.9969 - loss: 0.0112 - val_accuracy: 0.9803 - val_loss: 0.1201\n",
            "Epoch 25/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9758 - val_loss: 0.1673\n",
            "Epoch 26/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9966 - loss: 0.0119 - val_accuracy: 0.9765 - val_loss: 0.1506\n",
            "Epoch 27/30\n",
            "1875/1875 - 11s - 6ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 0.9799 - val_loss: 0.1380\n",
            "Epoch 28/30\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.9770 - val_loss: 0.1474\n",
            "Epoch 29/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9968 - loss: 0.0108 - val_accuracy: 0.9805 - val_loss: 0.1334\n",
            "Epoch 30/30\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9967 - loss: 0.0112 - val_accuracy: 0.9768 - val_loss: 0.1640\n",
            "Training Accuracy: 0.9955\n",
            "Testing Accuracy: 0.9768\n",
            "Architecture [256, 128, 64] - Testing Accuracy: 0.9829\n",
            "Architecture [128, 128] - Testing Accuracy: 0.9804\n",
            "Architecture [64, 64, 64] - Testing Accuracy: 0.9753\n",
            "Architecture [128, 256, 128] - Testing Accuracy: 0.9804\n",
            "Best Architecture: [256, 128, 64] with Testing Accuracy: 0.9829\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to [0,1] range\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the ANN model\n",
        "def build_model(hidden_layers=[128, 128, 128], activation='swish'):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    for neurons in hidden_layers:\n",
        "        model.add(Dense(neurons, activation=activation))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))  # Output layer\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initial model with given architecture\n",
        "model = build_model()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test), verbose=2)\n",
        "\n",
        "# Evaluate model\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(f'Training Accuracy: {train_acc:.4f}')\n",
        "print(f'Testing Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Experimenting with different architectures\n",
        "architectures = [\n",
        "    [256, 128, 64],  # More neurons per layer\n",
        "    [128, 128],       # Fewer layers\n",
        "    [64, 64, 64],     # Reduced neurons\n",
        "    [128, 256, 128]   # Altered neuron distribution\n",
        "]\n",
        "\n",
        "best_acc = 0\n",
        "best_architecture = None\n",
        "\n",
        "for arch in architectures:\n",
        "    model = build_model(hidden_layers=arch)\n",
        "    model.fit(x_train, y_train, epochs=30, batch_size=32, verbose=0, validation_data=(x_test, y_test))\n",
        "    _, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f'Architecture {arch} - Testing Accuracy: {test_acc:.4f}')\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_architecture = arch\n",
        "\n",
        "print(f'Best Architecture: {best_architecture} with Testing Accuracy: {best_acc:.4f}')\n"
      ]
    }
  ]
}