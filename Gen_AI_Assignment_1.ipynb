{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlC9rhqypAQcal9WoPh9HQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhuparusha225/Gen-AI-2025/blob/main/Gen_AI_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries?\n",
        "\n",
        "\n",
        "\n",
        "  YActual    _    YP red\n",
        "\n",
        "\n",
        "20    _   20.5\n",
        "\n",
        "\n",
        "30    _   30.3\n",
        "\n",
        "\n",
        "40    _   40.2\n",
        "\n",
        "\n",
        "50   _    50.6\n",
        "\n",
        "\n",
        "60     _  60.7\n",
        "\n",
        "\n",
        "Tabela 1: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "DZxEgvjAhfVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUhYTjNzf3t7"
      },
      "outputs": [],
      "source": [
        " import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YActual_reg = np.array([20, 30, 40, 50, 60])\n",
        "YPred_reg = np.array([20.5, 30.3, 40.2, 50.6, 60.7])"
      ],
      "metadata": {
        "id": "9_Yk8Xv6f5nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = np.mean(np.abs(YActual_reg - YPred_reg))\n",
        "mse = np.mean((YActual_reg - YPred_reg) ** 2)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(YActual_reg, YPred_reg)"
      ],
      "metadata": {
        "id": "G7pkqZKKf85V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Regression Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYdEYAqff_dh",
        "outputId": "fdcf5f90-5630-465c-dca6-6be7087de4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Metrics:\n",
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n",
            "R-squared (R²): 0.99877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLibrary-based Regression Metrics (from scikit-learn):\")\n",
        "print(f\"MAE (sklearn): {mean_absolute_error(YActual_reg, YPred_reg)}\")\n",
        "print(f\"MSE (sklearn): {mean_squared_error(YActual_reg, YPred_reg)}\")\n",
        "print(f\"R² (sklearn): {r2_score(YActual_reg, YPred_reg)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6dGL5KXgENI",
        "outputId": "dde13151-4e4b-4bd4-f865-2c38898280b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Library-based Regression Metrics (from scikit-learn):\n",
            "MAE (sklearn): 0.4600000000000016\n",
            "MSE (sklearn): 0.24600000000000147\n",
            "R² (sklearn): 0.99877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YActual_class = np.array([0, 0, 1, 1, 2, 0, 0, 1, 0, 2, 0, 2, 1, 0, 2, 2])\n",
        "YPred_class = np.array([0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 0, 2, 1, 2, 2, 2])"
      ],
      "metadata": {
        "id": "A_-Hwy-sgG_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(YActual_class, YPred_class)\n",
        "precision = precision_score(YActual_class, YPred_class, average='macro', zero_division=0)\n",
        "recall = recall_score(YActual_class, YPred_class, average='macro', zero_division=0)\n",
        "f1 = f1_score(YActual_class, YPred_class, average='macro', zero_division=0)\n",
        "conf_matrix = confusion_matrix(YActual_class, YPred_class)"
      ],
      "metadata": {
        "id": "p4UlSs8YgJdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQSnB5vugL1Y",
        "outputId": "cc836db9-ec8e-493a-b8e1-38d49e15b43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Metrics:\n",
            "Accuracy: 0.8125\n",
            "Precision: 0.8055555555555557\n",
            "Recall: 0.8214285714285715\n",
            "F1 Score: 0.8094405594405595\n",
            "Confusion Matrix:\n",
            "[[5 1 1]\n",
            " [1 3 0]\n",
            " [0 0 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLibrary-based Classification Metrics (from scikit-learn):\")\n",
        "print(f\"Accuracy (sklearn): {accuracy_score(YActual_class, YPred_class)}\")\n",
        "print(f\"Precision (sklearn): {precision_score(YActual_class, YPred_class, average='macro', zero_division=0)}\")\n",
        "print(f\"Recall (sklearn): {recall_score(YActual_class, YPred_class, average='macro', zero_division=0)}\")\n",
        "print(f\"F1 Score (sklearn): {f1_score(YActual_class, YPred_class, average='macro', zero_division=0)}\")\n",
        "print(f\"Confusion Matrix (sklearn):\\n{confusion_matrix(YActual_class, YPred_class)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJv5GfOkgOfG",
        "outputId": "35218a39-a61a-45a1-f249-72ad057f0319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Library-based Classification Metrics (from scikit-learn):\n",
            "Accuracy (sklearn): 0.8125\n",
            "Precision (sklearn): 0.8055555555555557\n",
            "Recall (sklearn): 0.8214285714285715\n",
            "F1 Score (sklearn): 0.8094405594405595\n",
            "Confusion Matrix (sklearn):\n",
            "[[5 1 1]\n",
            " [1 3 0]\n",
            " [0 0 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n",
        "\n",
        "\n",
        "YActual _ YP red\n",
        "\n",
        "\n",
        "0 _ 0 _ 1 1 2 0\n",
        "\n",
        "\n",
        "0 _ 0 _1 0 2 0\n",
        "\n",
        "\n",
        "0 _ 1 _ 1 2 2 1\n",
        "\n",
        "\n",
        "0 _ 2 _ 1 0 2 2\n",
        "\n",
        "\n",
        "0 _  2  _ 1 2 2 2\n",
        "\n",
        "\n",
        "Tabela 2: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "3Lsd5MtEk8wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "MlVFnNTmjXOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_actual = np.array([0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2])\n",
        "Y_pred = np.array([0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 2, 1, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2])"
      ],
      "metadata": {
        "id": "YtYd9R_BjXoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(Y_actual)"
      ],
      "metadata": {
        "id": "qOnV8P63jbAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_positive = {0: 0, 1: 0, 2: 0}\n",
        "false_positive = {0: 0, 1: 0, 2: 0}\n",
        "false_negative = {0: 0, 1: 0, 2: 0}\n",
        "true_negative = {0: 0, 1: 0, 2: 0}"
      ],
      "metadata": {
        "id": "u04iJhwMjdpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n):\n",
        "    for cls in [0, 1, 2]:\n",
        "        if Y_actual[i] == cls and Y_pred[i] == cls:\n",
        "            true_positive[cls] += 1\n",
        "        elif Y_actual[i] != cls and Y_pred[i] == cls:\n",
        "            false_positive[cls] += 1\n",
        "        elif Y_actual[i] == cls and Y_pred[i] != cls:\n",
        "            false_negative[cls] += 1\n",
        "        elif Y_actual[i] != cls and Y_pred[i] != cls:\n",
        "            true_negative[cls] += 1"
      ],
      "metadata": {
        "id": "83PDoHgmjfjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scratch = sum([true_positive[cls] for cls in [0, 1, 2]]) / n"
      ],
      "metadata": {
        "id": "-M4YS3eajh7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_scratch = {cls: true_positive[cls] / (true_positive[cls] + false_positive[cls]) if (true_positive[cls] + false_positive[cls]) > 0 else 0 for cls in [0, 1, 2]}\n",
        "recall_scratch = {cls: true_positive[cls] / (true_positive[cls] + false_negative[cls]) if (true_positive[cls] + false_negative[cls]) > 0 else 0 for cls in [0, 1, 2]}\n",
        "f1_score_scratch = {cls: 2 * precision_scratch[cls] * recall_scratch[cls] / (precision_scratch[cls] + recall_scratch[cls]) if (precision_scratch[cls] + recall_scratch[cls]) > 0 else 0 for cls in [0, 1, 2]}\n"
      ],
      "metadata": {
        "id": "EcEgK6wujkKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metrics calculated from scratch:\")\n",
        "print(f\"Accuracy: {accuracy_scratch}\")\n",
        "for cls in [0, 1, 2]:\n",
        "    print(f\"Class {cls} - Precision: {precision_scratch[cls]}, Recall: {recall_scratch[cls]}, F1-Score: {f1_score_scratch[cls]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhEij9QXjtCK",
        "outputId": "67b689c0-a655-4637-8751-e3dc78796fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics calculated from scratch:\n",
            "Accuracy: 0.7333333333333333\n",
            "Class 0 - Precision: 0.7777777777777778, Recall: 0.6363636363636364, F1-Score: 0.7000000000000001\n",
            "Class 1 - Precision: 0.7142857142857143, Recall: 0.625, F1-Score: 0.6666666666666666\n",
            "Class 2 - Precision: 0.7142857142857143, Recall: 0.9090909090909091, F1-Score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_library = accuracy_score(Y_actual, Y_pred)\n",
        "precision_library = precision_score(Y_actual, Y_pred, average=None)\n",
        "recall_library = recall_score(Y_actual, Y_pred, average=None)\n",
        "f1_library = f1_score(Y_actual, Y_pred, average=None)"
      ],
      "metadata": {
        "id": "r_oE1YK7j0lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMetrics calculated using libraries:\")\n",
        "print(f\"Accuracy: {accuracy_library}\")\n",
        "for cls, (p, r, f1) in enumerate(zip(precision_library, recall_library, f1_library)):\n",
        "    print(f\"Class {cls} - Precision: {p}, Recall: {r}, F1-Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewl5xgw8kBnR",
        "outputId": "9a944a9c-df77-4439-d3f8-2630028f9c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics calculated using libraries:\n",
            "Accuracy: 0.7333333333333333\n",
            "Class 0 - Precision: 0.7777777777777778, Recall: 0.6363636363636364, F1-Score: 0.7\n",
            "Class 1 - Precision: 0.7142857142857143, Recall: 0.625, F1-Score: 0.6666666666666666\n",
            "Class 2 - Precision: 0.7142857142857143, Recall: 0.9090909090909091, F1-Score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(Y_actual, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h6hIL3xkInX",
        "outputId": "1160a403-8025-45cb-986e-2c13104788db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.64      0.70        11\n",
            "           1       0.71      0.62      0.67         8\n",
            "           2       0.71      0.91      0.80        11\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.74      0.72      0.72        30\n",
            "weighted avg       0.74      0.73      0.73        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-o2gXxdkLiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}