{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF4x6DqtNlGwqIHvMUSVs4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhuparusha225/Gen-AI-2025/blob/main/2303A52207_Week_05_Assignment_5_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**P.Sindhu**\n",
        "\n",
        "**Batch:33**\n",
        "\n",
        "**2303A52207**"
      ],
      "metadata": {
        "id": "16c1YFyFul1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1 ponto) Design a multi-layer ANN architecture with one input, one hidden, and one output\n",
        "layer. Assume a linear activation function in the output layer and a sigmoid activation function\n",
        "in the hidden layer.\n",
        "\n",
        "• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "1.\n",
        "\n",
        "• Calculate the mean square error with training and testing data shown in Table 2.\n",
        "\n",
        "• Write Python code that reads the input data [x1 and x2] from the user. Predict the output\n",
        "with deployed ANN model\n",
        "Tabela 1: Training Data\n",
        "\n",
        "x1    x2    y\n",
        "\n",
        "0.1 0.2 0.3432\n",
        "\n",
        "0.2 0.3 0.3490\n",
        "\n",
        "0.3 0.4 0.3548\n",
        "\n",
        "0.6 0.7 0.3720\n",
        "\n",
        "0.7 0.8 0.3776\n",
        "\n",
        "0.8 0.9 0.3832\n",
        "\n",
        "Tabela 2: Test Data\n",
        "\n",
        "x1  x2  y\n",
        "\n",
        "0.4 0.5 0.3606\n",
        "\n",
        "0.5 0.6 0.3663"
      ],
      "metadata": {
        "id": "pcIdJK17u0iJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6L4QQdcsiyC",
        "outputId": "78a84f23-a83c-4ff5-8c7a-bd2a08489acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.335727\n",
            "Epoch 1000, Loss: 0.000110\n",
            "Epoch 2000, Loss: 0.000007\n",
            "Epoch 3000, Loss: 0.000000\n",
            "Epoch 4000, Loss: 0.000000\n",
            "Epoch 5000, Loss: 0.000000\n",
            "Epoch 6000, Loss: 0.000000\n",
            "Epoch 7000, Loss: 0.000000\n",
            "Epoch 8000, Loss: 0.000000\n",
            "Epoch 9000, Loss: 0.000000\n",
            "Training MSE: 6.503532693534658e-08\n",
            "Testing MSE: 1.875123358734216e-07\n",
            "Enter x1 and x2: 0.7 0.8\n",
            "Predicted Output: 0.37755931170812046\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def train_ann(X_train, y_train, hidden_neurons=3, learning_rate=0.1, epochs=10000):\n",
        "    np.random.seed(42)\n",
        "    input_neurons = X_train.shape[1]\n",
        "    output_neurons = 1\n",
        "\n",
        "    W1 = np.random.rand(input_neurons, hidden_neurons)\n",
        "    b1 = np.zeros((1, hidden_neurons))\n",
        "    W2 = np.random.rand(hidden_neurons, output_neurons)\n",
        "    b2 = np.zeros((1, output_neurons))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward propagation\n",
        "        Z1 = np.dot(X_train, W1) + b1\n",
        "        A1 = sigmoid(Z1)\n",
        "        Z2 = np.dot(A1, W2) + b2\n",
        "        A2 = Z2  # Linear activation\n",
        "\n",
        "        # Compute loss (Mean Squared Error)\n",
        "        loss = np.mean((A2 - y_train) ** 2)\n",
        "\n",
        "        # Backpropagation\n",
        "        dA2 = 2 * (A2 - y_train) / y_train.shape[0]\n",
        "        dW2 = np.dot(A1.T, dA2)\n",
        "        db2 = np.sum(dA2, axis=0, keepdims=True)\n",
        "        dA1 = np.dot(dA2, W2.T) * sigmoid_derivative(A1)\n",
        "        dW1 = np.dot(X_train.T, dA1)\n",
        "        db1 = np.sum(dA1, axis=0, keepdims=True)\n",
        "\n",
        "        # Update weights and biases\n",
        "        W1 -= learning_rate * dW1\n",
        "        b1 -= learning_rate * db1\n",
        "        W2 -= learning_rate * dW2\n",
        "        b2 -= learning_rate * db2\n",
        "\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def predict(X, W1, b1, W2, b2):\n",
        "    A1 = sigmoid(np.dot(X, W1) + b1)\n",
        "    return np.dot(A1, W2) + b2  # Linear activation\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Training Data\n",
        "X_train = np.array([[0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9]])\n",
        "y_train = np.array([[0.3432], [0.3490], [0.3548], [0.3720], [0.3776], [0.3832]])\n",
        "\n",
        "# Train the ANN\n",
        "W1, b1, W2, b2 = train_ann(X_train, y_train)\n",
        "\n",
        "# Test Data\n",
        "X_test = np.array([[0.4, 0.5], [0.5, 0.6]])\n",
        "y_test = np.array([[0.3606], [0.3663]])\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = predict(X_train, W1, b1, W2, b2)\n",
        "y_test_pred = predict(X_test, W1, b1, W2, b2)\n",
        "\n",
        "# Compute MSE\n",
        "print(\"Training MSE:\", mse(y_train, y_train_pred))\n",
        "print(\"Testing MSE:\", mse(y_test, y_test_pred))\n",
        "\n",
        "# User Input Prediction\n",
        "x1, x2 = map(float, input(\"Enter x1 and x2: \").split())\n",
        "user_pred = predict(np.array([[x1, x2]]), W1, b1, W2, b2)\n",
        "print(\"Predicted Output:\", user_pred[0][0])\n"
      ]
    }
  ]
}