{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmFUyIPXE3xeD1EWbAV2Xq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhuparusha225/Gen-AI-2025/blob/main/2303A52207_Week_08_Assignment_8_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (1 ponto) Design a multilayer ANN architecture according to the requirements shown below.\n",
        "Train, test, save (.h5) and deploy the model to predict the quality of wine using the Keras deep\n",
        "learning library\n",
        "\n",
        "2. (1 ponto) Calculate training and testing accuracy, build confusion matrix, also calculate recall,\n",
        "precision and F1-score.\n",
        "\n",
        "3. (1 ponto) Build the application by loading the saved ANN model.\n",
        "\n",
        "          Tabela 1: ANN Architecture\n",
        "        Layer             Neurons   Activation Function\n",
        "        Hidden Layer - 1  12          tanh\n",
        "        Hidden Layer - 2  24          tanh\n",
        "        Hidden Layer - 3  30          tanh\n",
        "        Hidden Layer - 4  20          tanh\n",
        "        Hidden Layer - 5  10          tanh\n",
        "          Tabela 2: Training Parameters\n",
        "        epochs  batch size  error metric  Optimizer\n",
        "        200      32          accuracy      adam\n",
        "Dataset: https://drive.google.com/file/d/1uutPAkOSYb2Uror1mk2dZUtoYbCgz6DO/view?\n",
        "usp=drive_link\n",
        "\n",
        "• Expected learning Outcomes from this assignment related to python\n",
        "\n",
        "– Students are able to build ANN model with python deep learning libraries\n",
        "\n",
        "– Students are able to deploy trained ANN model\n",
        "\n",
        "– Students are able to measure training and testing performance of trained model"
      ],
      "metadata": {
        "id": "zmbv7GPFVYnj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNMOIAWfUSRS",
        "outputId": "069f3115-cc19-4657-b81b-a23acdfc75ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -0.6769 - val_accuracy: 0.0000e+00 - val_loss: -6.8201\n",
            "Epoch 2/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -9.3698 - val_accuracy: 0.0000e+00 - val_loss: -16.6623\n",
            "Epoch 3/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -18.1045 - val_accuracy: 0.0000e+00 - val_loss: -21.6811\n",
            "Epoch 4/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -22.2579 - val_accuracy: 0.0000e+00 - val_loss: -24.8469\n",
            "Epoch 5/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -25.2849 - val_accuracy: 0.0000e+00 - val_loss: -27.5291\n",
            "Epoch 6/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -27.8949 - val_accuracy: 0.0000e+00 - val_loss: -30.0221\n",
            "Epoch 7/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -30.1718 - val_accuracy: 0.0000e+00 - val_loss: -32.4160\n",
            "Epoch 8/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -32.2190 - val_accuracy: 0.0000e+00 - val_loss: -34.7433\n",
            "Epoch 9/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -34.6552 - val_accuracy: 0.0000e+00 - val_loss: -37.0297\n",
            "Epoch 10/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -37.0806 - val_accuracy: 0.0000e+00 - val_loss: -39.2840\n",
            "Epoch 11/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -39.0480 - val_accuracy: 0.0000e+00 - val_loss: -41.5069\n",
            "Epoch 12/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -41.4212 - val_accuracy: 0.0000e+00 - val_loss: -43.7157\n",
            "Epoch 13/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -43.6853 - val_accuracy: 0.0000e+00 - val_loss: -45.9063\n",
            "Epoch 14/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -45.8674 - val_accuracy: 0.0000e+00 - val_loss: -48.0814\n",
            "Epoch 15/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -48.0968 - val_accuracy: 0.0000e+00 - val_loss: -50.2440\n",
            "Epoch 16/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -49.9524 - val_accuracy: 0.0000e+00 - val_loss: -52.3963\n",
            "Epoch 17/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -52.0098 - val_accuracy: 0.0000e+00 - val_loss: -54.5415\n",
            "Epoch 18/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -54.3192 - val_accuracy: 0.0000e+00 - val_loss: -56.6811\n",
            "Epoch 19/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -56.5050 - val_accuracy: 0.0000e+00 - val_loss: -58.8178\n",
            "Epoch 20/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -58.8632 - val_accuracy: 0.0000e+00 - val_loss: -60.9470\n",
            "Epoch 21/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -60.3675 - val_accuracy: 0.0000e+00 - val_loss: -63.0660\n",
            "Epoch 22/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -62.5940 - val_accuracy: 0.0000e+00 - val_loss: -65.1864\n",
            "Epoch 23/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -65.3160 - val_accuracy: 0.0000e+00 - val_loss: -67.3010\n",
            "Epoch 24/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -66.8281 - val_accuracy: 0.0000e+00 - val_loss: -69.4094\n",
            "Epoch 25/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -68.7519 - val_accuracy: 0.0000e+00 - val_loss: -71.5116\n",
            "Epoch 26/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -71.4017 - val_accuracy: 0.0000e+00 - val_loss: -73.6194\n",
            "Epoch 27/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -72.7469 - val_accuracy: 0.0000e+00 - val_loss: -75.7186\n",
            "Epoch 28/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -74.9989 - val_accuracy: 0.0000e+00 - val_loss: -77.8162\n",
            "Epoch 29/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -77.6471 - val_accuracy: 0.0000e+00 - val_loss: -79.9177\n",
            "Epoch 30/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -79.5115 - val_accuracy: 0.0000e+00 - val_loss: -82.0079\n",
            "Epoch 31/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -81.0957 - val_accuracy: 0.0000e+00 - val_loss: -84.1026\n",
            "Epoch 32/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -83.7468 - val_accuracy: 0.0000e+00 - val_loss: -86.1925\n",
            "Epoch 33/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -85.3628 - val_accuracy: 0.0000e+00 - val_loss: -88.2826\n",
            "Epoch 34/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -87.8555 - val_accuracy: 0.0000e+00 - val_loss: -90.3717\n",
            "Epoch 35/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -89.2910 - val_accuracy: 0.0000e+00 - val_loss: -92.4545\n",
            "Epoch 36/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -91.4999 - val_accuracy: 0.0000e+00 - val_loss: -94.5394\n",
            "Epoch 37/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -93.9068 - val_accuracy: 0.0000e+00 - val_loss: -96.6221\n",
            "Epoch 38/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -95.7501 - val_accuracy: 0.0000e+00 - val_loss: -98.7047\n",
            "Epoch 39/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -97.2221 - val_accuracy: 0.0000e+00 - val_loss: -100.7880\n",
            "Epoch 40/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -101.1152 - val_accuracy: 0.0000e+00 - val_loss: -102.8700\n",
            "Epoch 41/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -101.7488 - val_accuracy: 0.0000e+00 - val_loss: -104.9460\n",
            "Epoch 42/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -102.8118 - val_accuracy: 0.0000e+00 - val_loss: -107.0183\n",
            "Epoch 43/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -105.6221 - val_accuracy: 0.0000e+00 - val_loss: -109.0994\n",
            "Epoch 44/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -107.6833 - val_accuracy: 0.0000e+00 - val_loss: -111.1790\n",
            "Epoch 45/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -110.0407 - val_accuracy: 0.0000e+00 - val_loss: -113.2532\n",
            "Epoch 46/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -112.3419 - val_accuracy: 0.0000e+00 - val_loss: -115.3328\n",
            "Epoch 47/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -115.1516 - val_accuracy: 0.0000e+00 - val_loss: -117.4071\n",
            "Epoch 48/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -116.4163 - val_accuracy: 0.0000e+00 - val_loss: -119.4798\n",
            "Epoch 49/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -118.9502 - val_accuracy: 0.0000e+00 - val_loss: -121.5510\n",
            "Epoch 50/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -120.6852 - val_accuracy: 0.0000e+00 - val_loss: -123.6237\n",
            "Epoch 51/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -122.5692 - val_accuracy: 0.0000e+00 - val_loss: -125.6957\n",
            "Epoch 52/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -124.7832 - val_accuracy: 0.0000e+00 - val_loss: -127.7658\n",
            "Epoch 53/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -126.5786 - val_accuracy: 0.0000e+00 - val_loss: -129.8344\n",
            "Epoch 54/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -130.1023 - val_accuracy: 0.0000e+00 - val_loss: -131.9098\n",
            "Epoch 55/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -129.8387 - val_accuracy: 0.0000e+00 - val_loss: -133.9729\n",
            "Epoch 56/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -132.7077 - val_accuracy: 0.0000e+00 - val_loss: -136.0470\n",
            "Epoch 57/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -135.1868 - val_accuracy: 0.0000e+00 - val_loss: -138.1159\n",
            "Epoch 58/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -137.1214 - val_accuracy: 0.0000e+00 - val_loss: -140.1809\n",
            "Epoch 59/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -138.3409 - val_accuracy: 0.0000e+00 - val_loss: -142.2483\n",
            "Epoch 60/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -141.3541 - val_accuracy: 0.0000e+00 - val_loss: -144.3175\n",
            "Epoch 61/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -143.9439 - val_accuracy: 0.0000e+00 - val_loss: -146.3881\n",
            "Epoch 62/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -144.0460 - val_accuracy: 0.0000e+00 - val_loss: -148.4516\n",
            "Epoch 63/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -146.6810 - val_accuracy: 0.0000e+00 - val_loss: -150.5174\n",
            "Epoch 64/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -149.1099 - val_accuracy: 0.0000e+00 - val_loss: -152.5896\n",
            "Epoch 65/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -151.2292 - val_accuracy: 0.0000e+00 - val_loss: -154.6526\n",
            "Epoch 66/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -153.3286 - val_accuracy: 0.0000e+00 - val_loss: -156.7205\n",
            "Epoch 67/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -154.4249 - val_accuracy: 0.0000e+00 - val_loss: -158.7855\n",
            "Epoch 68/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -158.2590 - val_accuracy: 0.0000e+00 - val_loss: -160.8557\n",
            "Epoch 69/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -159.8730 - val_accuracy: 0.0000e+00 - val_loss: -162.9197\n",
            "Epoch 70/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -161.5782 - val_accuracy: 0.0000e+00 - val_loss: -164.9848\n",
            "Epoch 71/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -164.4922 - val_accuracy: 0.0000e+00 - val_loss: -167.0502\n",
            "Epoch 72/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -165.2129 - val_accuracy: 0.0000e+00 - val_loss: -169.1113\n",
            "Epoch 73/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -166.3810 - val_accuracy: 0.0000e+00 - val_loss: -171.1729\n",
            "Epoch 74/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -169.9962 - val_accuracy: 0.0000e+00 - val_loss: -173.2437\n",
            "Epoch 75/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -170.8694 - val_accuracy: 0.0000e+00 - val_loss: -175.3044\n",
            "Epoch 76/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -174.0911 - val_accuracy: 0.0000e+00 - val_loss: -177.3676\n",
            "Epoch 77/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -176.6350 - val_accuracy: 0.0000e+00 - val_loss: -179.4369\n",
            "Epoch 78/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -178.0818 - val_accuracy: 0.0000e+00 - val_loss: -181.4985\n",
            "Epoch 79/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -178.0373 - val_accuracy: 0.0000e+00 - val_loss: -183.5548\n",
            "Epoch 80/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -182.0765 - val_accuracy: 0.0000e+00 - val_loss: -185.6244\n",
            "Epoch 81/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -185.0631 - val_accuracy: 0.0000e+00 - val_loss: -187.6894\n",
            "Epoch 82/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -185.3250 - val_accuracy: 0.0000e+00 - val_loss: -189.7474\n",
            "Epoch 83/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -186.5708 - val_accuracy: 0.0000e+00 - val_loss: -191.8111\n",
            "Epoch 84/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -188.7461 - val_accuracy: 0.0000e+00 - val_loss: -193.8720\n",
            "Epoch 85/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -192.6095 - val_accuracy: 0.0000e+00 - val_loss: -195.9413\n",
            "Epoch 86/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -194.1415 - val_accuracy: 0.0000e+00 - val_loss: -198.0002\n",
            "Epoch 87/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -196.5760 - val_accuracy: 0.0000e+00 - val_loss: -200.0661\n",
            "Epoch 88/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -198.4106 - val_accuracy: 0.0000e+00 - val_loss: -202.1279\n",
            "Epoch 89/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -199.9960 - val_accuracy: 0.0000e+00 - val_loss: -204.1879\n",
            "Epoch 90/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -202.9483 - val_accuracy: 0.0000e+00 - val_loss: -206.2510\n",
            "Epoch 91/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -204.3505 - val_accuracy: 0.0000e+00 - val_loss: -208.3167\n",
            "Epoch 92/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -206.1069 - val_accuracy: 0.0000e+00 - val_loss: -210.3763\n",
            "Epoch 93/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -208.1563 - val_accuracy: 0.0000e+00 - val_loss: -212.4368\n",
            "Epoch 94/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -211.1447 - val_accuracy: 0.0000e+00 - val_loss: -214.5001\n",
            "Epoch 95/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -210.7036 - val_accuracy: 0.0000e+00 - val_loss: -216.5580\n",
            "Epoch 96/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -215.2564 - val_accuracy: 0.0000e+00 - val_loss: -218.6261\n",
            "Epoch 97/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -216.2323 - val_accuracy: 0.0000e+00 - val_loss: -220.6848\n",
            "Epoch 98/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -218.8675 - val_accuracy: 0.0000e+00 - val_loss: -222.7505\n",
            "Epoch 99/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -220.2579 - val_accuracy: 0.0000e+00 - val_loss: -224.8080\n",
            "Epoch 100/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -221.8749 - val_accuracy: 0.0000e+00 - val_loss: -226.8719\n",
            "Epoch 101/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -225.7783 - val_accuracy: 0.0000e+00 - val_loss: -228.9336\n",
            "Epoch 102/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -226.4612 - val_accuracy: 0.0000e+00 - val_loss: -230.9932\n",
            "Epoch 103/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -229.7989 - val_accuracy: 0.0000e+00 - val_loss: -233.0606\n",
            "Epoch 104/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -229.8400 - val_accuracy: 0.0000e+00 - val_loss: -235.1165\n",
            "Epoch 105/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -233.3043 - val_accuracy: 0.0000e+00 - val_loss: -237.1782\n",
            "Epoch 106/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -235.5135 - val_accuracy: 0.0000e+00 - val_loss: -239.2405\n",
            "Epoch 107/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -236.6550 - val_accuracy: 0.0000e+00 - val_loss: -241.3055\n",
            "Epoch 108/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -238.4026 - val_accuracy: 0.0000e+00 - val_loss: -243.3611\n",
            "Epoch 109/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -239.7221 - val_accuracy: 0.0000e+00 - val_loss: -245.4202\n",
            "Epoch 110/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -243.3208 - val_accuracy: 0.0000e+00 - val_loss: -247.4813\n",
            "Epoch 111/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -245.3484 - val_accuracy: 0.0000e+00 - val_loss: -249.5453\n",
            "Epoch 112/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -247.7916 - val_accuracy: 0.0000e+00 - val_loss: -251.6070\n",
            "Epoch 113/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -246.9583 - val_accuracy: 0.0000e+00 - val_loss: -253.6642\n",
            "Epoch 114/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -250.5423 - val_accuracy: 0.0000e+00 - val_loss: -255.7316\n",
            "Epoch 115/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -251.7394 - val_accuracy: 0.0000e+00 - val_loss: -257.7894\n",
            "Epoch 116/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -254.9927 - val_accuracy: 0.0000e+00 - val_loss: -259.8503\n",
            "Epoch 117/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: -257.7844 - val_accuracy: 0.0000e+00 - val_loss: -261.9122\n",
            "Epoch 118/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -257.9633 - val_accuracy: 0.0000e+00 - val_loss: -263.9708\n",
            "Epoch 119/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: -261.0912 - val_accuracy: 0.0000e+00 - val_loss: -266.0319\n",
            "Epoch 120/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: -263.7621 - val_accuracy: 0.0000e+00 - val_loss: -268.0897\n",
            "Epoch 121/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: -265.0236 - val_accuracy: 0.0000e+00 - val_loss: -270.1549\n",
            "Epoch 122/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -268.4409 - val_accuracy: 0.0000e+00 - val_loss: -272.2149\n",
            "Epoch 123/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -268.4078 - val_accuracy: 0.0000e+00 - val_loss: -274.2728\n",
            "Epoch 124/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -270.7856 - val_accuracy: 0.0000e+00 - val_loss: -276.3343\n",
            "Epoch 125/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -272.3331 - val_accuracy: 0.0000e+00 - val_loss: -278.3930\n",
            "Epoch 126/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -274.7854 - val_accuracy: 0.0000e+00 - val_loss: -280.4567\n",
            "Epoch 127/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -276.8455 - val_accuracy: 0.0000e+00 - val_loss: -282.5187\n",
            "Epoch 128/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -278.5427 - val_accuracy: 0.0000e+00 - val_loss: -284.5789\n",
            "Epoch 129/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -281.9898 - val_accuracy: 0.0000e+00 - val_loss: -286.6374\n",
            "Epoch 130/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -281.4012 - val_accuracy: 0.0000e+00 - val_loss: -288.6975\n",
            "Epoch 131/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -284.4861 - val_accuracy: 0.0000e+00 - val_loss: -290.7585\n",
            "Epoch 132/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -287.5006 - val_accuracy: 0.0000e+00 - val_loss: -292.8251\n",
            "Epoch 133/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -289.4858 - val_accuracy: 0.0000e+00 - val_loss: -294.8845\n",
            "Epoch 134/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -293.7859 - val_accuracy: 0.0000e+00 - val_loss: -296.9482\n",
            "Epoch 135/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -291.4822 - val_accuracy: 0.0000e+00 - val_loss: -299.0016\n",
            "Epoch 136/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -294.8081 - val_accuracy: 0.0000e+00 - val_loss: -301.0636\n",
            "Epoch 137/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -296.9118 - val_accuracy: 0.0000e+00 - val_loss: -303.1249\n",
            "Epoch 138/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -300.1940 - val_accuracy: 0.0000e+00 - val_loss: -305.1895\n",
            "Epoch 139/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -302.7840 - val_accuracy: 0.0000e+00 - val_loss: -307.2480\n",
            "Epoch 140/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -302.3331 - val_accuracy: 0.0000e+00 - val_loss: -309.3049\n",
            "Epoch 141/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -307.1512 - val_accuracy: 0.0000e+00 - val_loss: -311.3673\n",
            "Epoch 142/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -309.2263 - val_accuracy: 0.0000e+00 - val_loss: -313.4338\n",
            "Epoch 143/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -307.8357 - val_accuracy: 0.0000e+00 - val_loss: -315.4859\n",
            "Epoch 144/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -310.9144 - val_accuracy: 0.0000e+00 - val_loss: -317.5525\n",
            "Epoch 145/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -315.2333 - val_accuracy: 0.0000e+00 - val_loss: -319.6100\n",
            "Epoch 146/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -315.8336 - val_accuracy: 0.0000e+00 - val_loss: -321.6690\n",
            "Epoch 147/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -319.5034 - val_accuracy: 0.0000e+00 - val_loss: -323.7307\n",
            "Epoch 148/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -321.3830 - val_accuracy: 0.0000e+00 - val_loss: -325.7921\n",
            "Epoch 149/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -322.8220 - val_accuracy: 0.0000e+00 - val_loss: -327.8499\n",
            "Epoch 150/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -325.1855 - val_accuracy: 0.0000e+00 - val_loss: -329.9122\n",
            "Epoch 151/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -323.8763 - val_accuracy: 0.0000e+00 - val_loss: -331.9685\n",
            "Epoch 152/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -330.0320 - val_accuracy: 0.0000e+00 - val_loss: -334.0348\n",
            "Epoch 153/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -328.5026 - val_accuracy: 0.0000e+00 - val_loss: -336.0876\n",
            "Epoch 154/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -334.9465 - val_accuracy: 0.0000e+00 - val_loss: -338.1509\n",
            "Epoch 155/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -334.3773 - val_accuracy: 0.0000e+00 - val_loss: -340.2140\n",
            "Epoch 156/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -334.7962 - val_accuracy: 0.0000e+00 - val_loss: -342.2735\n",
            "Epoch 157/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -336.5472 - val_accuracy: 0.0000e+00 - val_loss: -344.3301\n",
            "Epoch 158/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -343.2909 - val_accuracy: 0.0000e+00 - val_loss: -346.3984\n",
            "Epoch 159/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -342.8624 - val_accuracy: 0.0000e+00 - val_loss: -348.4547\n",
            "Epoch 160/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -344.8909 - val_accuracy: 0.0000e+00 - val_loss: -350.5121\n",
            "Epoch 161/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -347.3483 - val_accuracy: 0.0000e+00 - val_loss: -352.5744\n",
            "Epoch 162/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -350.2614 - val_accuracy: 0.0000e+00 - val_loss: -354.6335\n",
            "Epoch 163/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -350.0594 - val_accuracy: 0.0000e+00 - val_loss: -356.6938\n",
            "Epoch 164/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -350.8136 - val_accuracy: 0.0000e+00 - val_loss: -358.7494\n",
            "Epoch 165/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -353.5477 - val_accuracy: 0.0000e+00 - val_loss: -360.8123\n",
            "Epoch 166/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -357.1752 - val_accuracy: 0.0000e+00 - val_loss: -362.8779\n",
            "Epoch 167/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -358.7211 - val_accuracy: 0.0000e+00 - val_loss: -364.9362\n",
            "Epoch 168/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -360.8494 - val_accuracy: 0.0000e+00 - val_loss: -366.9976\n",
            "Epoch 169/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -361.9138 - val_accuracy: 0.0000e+00 - val_loss: -369.0555\n",
            "Epoch 170/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -363.3448 - val_accuracy: 0.0000e+00 - val_loss: -371.1106\n",
            "Epoch 171/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -367.5499 - val_accuracy: 0.0000e+00 - val_loss: -373.1752\n",
            "Epoch 172/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -367.1859 - val_accuracy: 0.0000e+00 - val_loss: -375.2354\n",
            "Epoch 173/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -373.7623 - val_accuracy: 0.0000e+00 - val_loss: -377.2988\n",
            "Epoch 174/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: -374.2796 - val_accuracy: 0.0000e+00 - val_loss: -379.3585\n",
            "Epoch 175/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -374.7483 - val_accuracy: 0.0000e+00 - val_loss: -381.4192\n",
            "Epoch 176/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -378.8029 - val_accuracy: 0.0000e+00 - val_loss: -383.4749\n",
            "Epoch 177/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -379.6041 - val_accuracy: 0.0000e+00 - val_loss: -385.5392\n",
            "Epoch 178/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -381.9549 - val_accuracy: 0.0000e+00 - val_loss: -387.6009\n",
            "Epoch 179/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -380.9829 - val_accuracy: 0.0000e+00 - val_loss: -389.6545\n",
            "Epoch 180/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -386.9132 - val_accuracy: 0.0000e+00 - val_loss: -391.7213\n",
            "Epoch 181/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -387.1962 - val_accuracy: 0.0000e+00 - val_loss: -393.7806\n",
            "Epoch 182/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -389.3550 - val_accuracy: 0.0000e+00 - val_loss: -395.8386\n",
            "Epoch 183/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -386.8165 - val_accuracy: 0.0000e+00 - val_loss: -397.8955\n",
            "Epoch 184/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -391.4971 - val_accuracy: 0.0000e+00 - val_loss: -399.9592\n",
            "Epoch 185/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -396.5883 - val_accuracy: 0.0000e+00 - val_loss: -402.0221\n",
            "Epoch 186/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -397.3367 - val_accuracy: 0.0000e+00 - val_loss: -404.0789\n",
            "Epoch 187/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -400.1080 - val_accuracy: 0.0000e+00 - val_loss: -406.1406\n",
            "Epoch 188/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -402.3686 - val_accuracy: 0.0000e+00 - val_loss: -408.2026\n",
            "Epoch 189/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -404.2516 - val_accuracy: 0.0000e+00 - val_loss: -410.2627\n",
            "Epoch 190/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -405.8820 - val_accuracy: 0.0000e+00 - val_loss: -412.3187\n",
            "Epoch 191/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -405.3047 - val_accuracy: 0.0000e+00 - val_loss: -414.3793\n",
            "Epoch 192/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -410.5553 - val_accuracy: 0.0000e+00 - val_loss: -416.4424\n",
            "Epoch 193/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -412.9165 - val_accuracy: 0.0000e+00 - val_loss: -418.5023\n",
            "Epoch 194/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -414.3742 - val_accuracy: 0.0000e+00 - val_loss: -420.5609\n",
            "Epoch 195/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -417.5058 - val_accuracy: 0.0000e+00 - val_loss: -422.6218\n",
            "Epoch 196/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -415.4269 - val_accuracy: 0.0000e+00 - val_loss: -424.6794\n",
            "Epoch 197/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -419.8832 - val_accuracy: 0.0000e+00 - val_loss: -426.7400\n",
            "Epoch 198/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -422.9409 - val_accuracy: 0.0000e+00 - val_loss: -428.8013\n",
            "Epoch 199/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -424.2660 - val_accuracy: 0.0000e+00 - val_loss: -430.8661\n",
            "Epoch 200/200\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -427.2783 - val_accuracy: 0.0000e+00 - val_loss: -432.9266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.0\n",
            "Confusion Matrix:\n",
            "[[  0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0]\n",
            " [ 10   0   0   0   0   0   0]\n",
            " [130   0   0   0   0   0   0]\n",
            " [132   0   0   0   0   0   0]\n",
            " [ 42   0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "           3       0.00      0.00      0.00       1.0\n",
            "           4       0.00      0.00      0.00      10.0\n",
            "           5       0.00      0.00      0.00     130.0\n",
            "           6       0.00      0.00      0.00     132.0\n",
            "           7       0.00      0.00      0.00      42.0\n",
            "           8       0.00      0.00      0.00       5.0\n",
            "\n",
            "    accuracy                           0.00     320.0\n",
            "   macro avg       0.00      0.00      0.00     320.0\n",
            "weighted avg       0.00      0.00      0.00     320.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "Predicted Wine Quality: Good Quality\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load dataset (replace with actual path after downloading manually)\n",
        "dataset_path = \"/content/winequality-red.csv\"  # Modify as per actual filename\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Convert categorical features to numeric using one-hot encoding (if applicable)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Assuming last column is target and rest are features\n",
        "X = df.iloc[:, :-1].values  # Features\n",
        "y = df.iloc[:, -1].values   # Target (classification)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define ANN model\n",
        "model = Sequential([\n",
        "    Dense(12, activation='tanh', input_shape=(X_train.shape[1],)),\n",
        "    Dense(24, activation='tanh'),\n",
        "    Dense(30, activation='tanh'),\n",
        "    Dense(20, activation='tanh'),\n",
        "    Dense(10, activation='tanh'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the model\n",
        "model.save(\"wine_quality_model.h5\")\n",
        "\n",
        "# Load the saved model for deployment\n",
        "loaded_model = keras.models.load_model(\"wine_quality_model.h5\")\n",
        "\n",
        "# Evaluate performance\n",
        "y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
        "y_test_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Deploy: Predict wine quality for a new input (example)\n",
        "def predict_wine_quality(input_features):\n",
        "    input_scaled = scaler.transform([input_features])\n",
        "    prediction = loaded_model.predict(input_scaled)\n",
        "    return \"Good Quality\" if prediction[0][0] > 0.5 else \"Poor Quality\"\n",
        "\n",
        "# Example usage\n",
        "new_sample = X_test[0]  # Example test data\n",
        "predicted_quality = predict_wine_quality(new_sample)\n",
        "print(f\"Predicted Wine Quality: {predicted_quality}\")\n"
      ]
    }
  ]
}