{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDXwufE9FvT/9ZOM7O0QZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhuparusha225/Gen-AI-2025/blob/main/2303A52207_Week_07_Assignment_7_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (1 ponto) Design a multilayer ANN architecture according to the requirements shown below.\n",
        "Train, test, save (.h5) and deploy the model to diagnose diabatic disease using the Keras deep\n",
        "learning library\n",
        "\n",
        "2. (1 ponto) Calculate training and testing accuracy, build confusion matrix, also calculate recall,\n",
        "precision and F1-score.\n",
        "\n",
        "3. (1 ponto) Build the application by loading the saved ANN model.\n",
        "\n",
        "        Tabela 1: ANN Architecture\n",
        "        Layer              Neurons   Activation Function\n",
        "        Hidden Layer - 1     12        swish\n",
        "        Hidden Layer - 2     25        swish\n",
        "        Hidden Layer - 3     15        swish\n",
        "\n",
        "        Tabela 2: Training Parameters\n",
        "        epochs   batch size   error metric   Optimizer\n",
        "        300        16          accuracy       adagrad\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset?resource=download\n",
        "\n",
        "• Expected learning Outcomes from this assignment related to python\n",
        "\n",
        "– Students are able to build ANN model with python deep learning libraries\n",
        "\n",
        "– Students are able to deploy trained ANN model\n",
        "\n",
        "– Students are able to measure training and testing performance of trained mode"
      ],
      "metadata": {
        "id": "Okq7ApcWKHf_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9WRYTVH8KCgu",
        "outputId": "6f990516-aa30-40e3-9e65-525ad0a66011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "Training set: (614, 8), Testing set: (154, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4094 - loss: 0.7188 - val_accuracy: 0.4740 - val_loss: 0.7229\n",
            "Epoch 2/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4493 - loss: 0.7158 - val_accuracy: 0.4870 - val_loss: 0.7181\n",
            "Epoch 3/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4624 - loss: 0.7112 - val_accuracy: 0.5195 - val_loss: 0.7138\n",
            "Epoch 4/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5349 - loss: 0.6974 - val_accuracy: 0.5390 - val_loss: 0.7099\n",
            "Epoch 5/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5584 - loss: 0.6981 - val_accuracy: 0.5519 - val_loss: 0.7064\n",
            "Epoch 6/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5446 - loss: 0.7008 - val_accuracy: 0.5649 - val_loss: 0.7031\n",
            "Epoch 7/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5679 - loss: 0.6944 - val_accuracy: 0.5779 - val_loss: 0.6999\n",
            "Epoch 8/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6095 - loss: 0.6914 - val_accuracy: 0.5779 - val_loss: 0.6969\n",
            "Epoch 9/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5941 - loss: 0.6849 - val_accuracy: 0.5909 - val_loss: 0.6940\n",
            "Epoch 10/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6291 - loss: 0.6859 - val_accuracy: 0.6104 - val_loss: 0.6913\n",
            "Epoch 11/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.6813 - val_accuracy: 0.6299 - val_loss: 0.6887\n",
            "Epoch 12/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.6794 - val_accuracy: 0.6429 - val_loss: 0.6862\n",
            "Epoch 13/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6862 - loss: 0.6705 - val_accuracy: 0.6299 - val_loss: 0.6837\n",
            "Epoch 14/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6414 - loss: 0.6779 - val_accuracy: 0.6299 - val_loss: 0.6814\n",
            "Epoch 15/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6412 - loss: 0.6770 - val_accuracy: 0.6429 - val_loss: 0.6791\n",
            "Epoch 16/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6504 - loss: 0.6753 - val_accuracy: 0.6429 - val_loss: 0.6769\n",
            "Epoch 17/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 0.6731 - val_accuracy: 0.6494 - val_loss: 0.6747\n",
            "Epoch 18/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.6658 - val_accuracy: 0.6558 - val_loss: 0.6726\n",
            "Epoch 19/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6428 - loss: 0.6706 - val_accuracy: 0.6558 - val_loss: 0.6705\n",
            "Epoch 20/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6641 - loss: 0.6641 - val_accuracy: 0.6558 - val_loss: 0.6684\n",
            "Epoch 21/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.6634 - val_accuracy: 0.6558 - val_loss: 0.6665\n",
            "Epoch 22/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 0.6568 - val_accuracy: 0.6558 - val_loss: 0.6645\n",
            "Epoch 23/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6724 - loss: 0.6585 - val_accuracy: 0.6558 - val_loss: 0.6626\n",
            "Epoch 24/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7007 - loss: 0.6465 - val_accuracy: 0.6558 - val_loss: 0.6607\n",
            "Epoch 25/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6774 - loss: 0.6518 - val_accuracy: 0.6558 - val_loss: 0.6589\n",
            "Epoch 26/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6566 - loss: 0.6568 - val_accuracy: 0.6623 - val_loss: 0.6570\n",
            "Epoch 27/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6754 - loss: 0.6482 - val_accuracy: 0.6623 - val_loss: 0.6552\n",
            "Epoch 28/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6913 - loss: 0.6414 - val_accuracy: 0.6688 - val_loss: 0.6534\n",
            "Epoch 29/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6773 - loss: 0.6474 - val_accuracy: 0.6688 - val_loss: 0.6516\n",
            "Epoch 30/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 0.6395 - val_accuracy: 0.6688 - val_loss: 0.6498\n",
            "Epoch 31/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6724 - loss: 0.6425 - val_accuracy: 0.6688 - val_loss: 0.6481\n",
            "Epoch 32/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.6359 - val_accuracy: 0.6753 - val_loss: 0.6464\n",
            "Epoch 33/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6804 - loss: 0.6379 - val_accuracy: 0.6753 - val_loss: 0.6447\n",
            "Epoch 34/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6824 - loss: 0.6372 - val_accuracy: 0.6753 - val_loss: 0.6430\n",
            "Epoch 35/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6818 - loss: 0.6340 - val_accuracy: 0.6688 - val_loss: 0.6414\n",
            "Epoch 36/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6885 - loss: 0.6280 - val_accuracy: 0.6688 - val_loss: 0.6398\n",
            "Epoch 37/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6515 - loss: 0.6402 - val_accuracy: 0.6688 - val_loss: 0.6382\n",
            "Epoch 38/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6989 - loss: 0.6273 - val_accuracy: 0.6753 - val_loss: 0.6366\n",
            "Epoch 39/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6900 - loss: 0.6290 - val_accuracy: 0.6753 - val_loss: 0.6350\n",
            "Epoch 40/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6898 - loss: 0.6291 - val_accuracy: 0.6753 - val_loss: 0.6335\n",
            "Epoch 41/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.6194 - val_accuracy: 0.6753 - val_loss: 0.6319\n",
            "Epoch 42/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7063 - loss: 0.6199 - val_accuracy: 0.6818 - val_loss: 0.6304\n",
            "Epoch 43/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6840 - loss: 0.6206 - val_accuracy: 0.6753 - val_loss: 0.6289\n",
            "Epoch 44/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.6155 - val_accuracy: 0.6753 - val_loss: 0.6274\n",
            "Epoch 45/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7001 - loss: 0.6191 - val_accuracy: 0.6753 - val_loss: 0.6259\n",
            "Epoch 46/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7031 - loss: 0.6185 - val_accuracy: 0.6753 - val_loss: 0.6244\n",
            "Epoch 47/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7089 - loss: 0.6146 - val_accuracy: 0.6753 - val_loss: 0.6229\n",
            "Epoch 48/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.6185 - val_accuracy: 0.6688 - val_loss: 0.6215\n",
            "Epoch 49/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6919 - loss: 0.6155 - val_accuracy: 0.6688 - val_loss: 0.6201\n",
            "Epoch 50/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 0.6153 - val_accuracy: 0.6558 - val_loss: 0.6186\n",
            "Epoch 51/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7056 - loss: 0.6133 - val_accuracy: 0.6558 - val_loss: 0.6172\n",
            "Epoch 52/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.6038 - val_accuracy: 0.6558 - val_loss: 0.6158\n",
            "Epoch 53/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7186 - loss: 0.6047 - val_accuracy: 0.6558 - val_loss: 0.6144\n",
            "Epoch 54/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7232 - loss: 0.5918 - val_accuracy: 0.6558 - val_loss: 0.6130\n",
            "Epoch 55/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7091 - loss: 0.6019 - val_accuracy: 0.6558 - val_loss: 0.6116\n",
            "Epoch 56/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.6009 - val_accuracy: 0.6558 - val_loss: 0.6103\n",
            "Epoch 57/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.6096 - val_accuracy: 0.6558 - val_loss: 0.6089\n",
            "Epoch 58/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.5884 - val_accuracy: 0.6558 - val_loss: 0.6076\n",
            "Epoch 59/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7099 - loss: 0.5977 - val_accuracy: 0.6688 - val_loss: 0.6063\n",
            "Epoch 60/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.5965 - val_accuracy: 0.6688 - val_loss: 0.6050\n",
            "Epoch 61/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7014 - loss: 0.6021 - val_accuracy: 0.6688 - val_loss: 0.6037\n",
            "Epoch 62/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.5914 - val_accuracy: 0.6623 - val_loss: 0.6024\n",
            "Epoch 63/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.5908 - val_accuracy: 0.6623 - val_loss: 0.6011\n",
            "Epoch 64/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.5909 - val_accuracy: 0.6623 - val_loss: 0.5999\n",
            "Epoch 65/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 0.5919 - val_accuracy: 0.6753 - val_loss: 0.5986\n",
            "Epoch 66/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.5863 - val_accuracy: 0.6753 - val_loss: 0.5974\n",
            "Epoch 67/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.5778 - val_accuracy: 0.6753 - val_loss: 0.5962\n",
            "Epoch 68/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.5723 - val_accuracy: 0.6688 - val_loss: 0.5950\n",
            "Epoch 69/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.5907 - val_accuracy: 0.6688 - val_loss: 0.5938\n",
            "Epoch 70/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7107 - loss: 0.5903 - val_accuracy: 0.6688 - val_loss: 0.5926\n",
            "Epoch 71/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7244 - loss: 0.5946 - val_accuracy: 0.6753 - val_loss: 0.5914\n",
            "Epoch 72/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.5832 - val_accuracy: 0.6753 - val_loss: 0.5902\n",
            "Epoch 73/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7230 - loss: 0.5823 - val_accuracy: 0.6818 - val_loss: 0.5891\n",
            "Epoch 74/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7046 - loss: 0.5855 - val_accuracy: 0.6818 - val_loss: 0.5879\n",
            "Epoch 75/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.5823 - val_accuracy: 0.6818 - val_loss: 0.5868\n",
            "Epoch 76/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7357 - loss: 0.5676 - val_accuracy: 0.6818 - val_loss: 0.5857\n",
            "Epoch 77/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7382 - loss: 0.5656 - val_accuracy: 0.6818 - val_loss: 0.5846\n",
            "Epoch 78/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7243 - loss: 0.5770 - val_accuracy: 0.6818 - val_loss: 0.5835\n",
            "Epoch 79/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7564 - loss: 0.5686 - val_accuracy: 0.6818 - val_loss: 0.5825\n",
            "Epoch 80/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7375 - loss: 0.5720 - val_accuracy: 0.6818 - val_loss: 0.5814\n",
            "Epoch 81/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7513 - loss: 0.5650 - val_accuracy: 0.6818 - val_loss: 0.5804\n",
            "Epoch 82/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.5460 - val_accuracy: 0.6883 - val_loss: 0.5793\n",
            "Epoch 83/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7344 - loss: 0.5617 - val_accuracy: 0.6948 - val_loss: 0.5784\n",
            "Epoch 84/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.5729 - val_accuracy: 0.6948 - val_loss: 0.5774\n",
            "Epoch 85/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.5623 - val_accuracy: 0.6948 - val_loss: 0.5764\n",
            "Epoch 86/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.5673 - val_accuracy: 0.6948 - val_loss: 0.5754\n",
            "Epoch 87/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.5690 - val_accuracy: 0.6948 - val_loss: 0.5744\n",
            "Epoch 88/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.5616 - val_accuracy: 0.6948 - val_loss: 0.5735\n",
            "Epoch 89/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7601 - loss: 0.5461 - val_accuracy: 0.6948 - val_loss: 0.5726\n",
            "Epoch 90/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7420 - loss: 0.5565 - val_accuracy: 0.6883 - val_loss: 0.5717\n",
            "Epoch 91/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.5555 - val_accuracy: 0.6883 - val_loss: 0.5708\n",
            "Epoch 92/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.5406 - val_accuracy: 0.6883 - val_loss: 0.5699\n",
            "Epoch 93/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.5631 - val_accuracy: 0.6948 - val_loss: 0.5690\n",
            "Epoch 94/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7268 - loss: 0.5592 - val_accuracy: 0.6948 - val_loss: 0.5681\n",
            "Epoch 95/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7093 - loss: 0.5852 - val_accuracy: 0.6948 - val_loss: 0.5672\n",
            "Epoch 96/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7573 - loss: 0.5536 - val_accuracy: 0.7013 - val_loss: 0.5664\n",
            "Epoch 97/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7585 - loss: 0.5412 - val_accuracy: 0.7078 - val_loss: 0.5655\n",
            "Epoch 98/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7458 - loss: 0.5608 - val_accuracy: 0.7078 - val_loss: 0.5647\n",
            "Epoch 99/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.5529 - val_accuracy: 0.7013 - val_loss: 0.5639\n",
            "Epoch 100/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.5428 - val_accuracy: 0.7013 - val_loss: 0.5631\n",
            "Epoch 101/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7693 - loss: 0.5349 - val_accuracy: 0.7013 - val_loss: 0.5623\n",
            "Epoch 102/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.5596 - val_accuracy: 0.7013 - val_loss: 0.5616\n",
            "Epoch 103/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.5516 - val_accuracy: 0.7078 - val_loss: 0.5608\n",
            "Epoch 104/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.5352 - val_accuracy: 0.7078 - val_loss: 0.5601\n",
            "Epoch 105/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7516 - loss: 0.5442 - val_accuracy: 0.7013 - val_loss: 0.5593\n",
            "Epoch 106/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7473 - loss: 0.5458 - val_accuracy: 0.7013 - val_loss: 0.5586\n",
            "Epoch 107/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7538 - loss: 0.5373 - val_accuracy: 0.6948 - val_loss: 0.5579\n",
            "Epoch 108/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7496 - loss: 0.5374 - val_accuracy: 0.6948 - val_loss: 0.5572\n",
            "Epoch 109/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7754 - loss: 0.5391 - val_accuracy: 0.6948 - val_loss: 0.5565\n",
            "Epoch 110/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.5317 - val_accuracy: 0.6948 - val_loss: 0.5558\n",
            "Epoch 111/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.5320 - val_accuracy: 0.6948 - val_loss: 0.5551\n",
            "Epoch 112/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7803 - loss: 0.5332 - val_accuracy: 0.6948 - val_loss: 0.5545\n",
            "Epoch 113/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7525 - loss: 0.5304 - val_accuracy: 0.6883 - val_loss: 0.5538\n",
            "Epoch 114/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 0.5404 - val_accuracy: 0.6948 - val_loss: 0.5532\n",
            "Epoch 115/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.5276 - val_accuracy: 0.6948 - val_loss: 0.5525\n",
            "Epoch 116/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.5345 - val_accuracy: 0.6948 - val_loss: 0.5519\n",
            "Epoch 117/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.5383 - val_accuracy: 0.6948 - val_loss: 0.5513\n",
            "Epoch 118/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.5334 - val_accuracy: 0.6948 - val_loss: 0.5507\n",
            "Epoch 119/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7395 - loss: 0.5300 - val_accuracy: 0.6948 - val_loss: 0.5501\n",
            "Epoch 120/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7176 - loss: 0.5502 - val_accuracy: 0.6948 - val_loss: 0.5495\n",
            "Epoch 121/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7476 - loss: 0.5412 - val_accuracy: 0.6948 - val_loss: 0.5489\n",
            "Epoch 122/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7826 - loss: 0.5119 - val_accuracy: 0.6948 - val_loss: 0.5484\n",
            "Epoch 123/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 0.5455 - val_accuracy: 0.6948 - val_loss: 0.5478\n",
            "Epoch 124/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7555 - loss: 0.5252 - val_accuracy: 0.7013 - val_loss: 0.5472\n",
            "Epoch 125/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7584 - loss: 0.5278 - val_accuracy: 0.7013 - val_loss: 0.5467\n",
            "Epoch 126/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.5707 - val_accuracy: 0.7013 - val_loss: 0.5462\n",
            "Epoch 127/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5245 - val_accuracy: 0.7013 - val_loss: 0.5457\n",
            "Epoch 128/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7676 - loss: 0.5225 - val_accuracy: 0.7013 - val_loss: 0.5452\n",
            "Epoch 129/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7555 - loss: 0.5378 - val_accuracy: 0.7013 - val_loss: 0.5447\n",
            "Epoch 130/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.5372 - val_accuracy: 0.7013 - val_loss: 0.5441\n",
            "Epoch 131/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.5041 - val_accuracy: 0.7013 - val_loss: 0.5437\n",
            "Epoch 132/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5192 - val_accuracy: 0.7013 - val_loss: 0.5432\n",
            "Epoch 133/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.5149 - val_accuracy: 0.7013 - val_loss: 0.5428\n",
            "Epoch 134/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.5293 - val_accuracy: 0.7013 - val_loss: 0.5423\n",
            "Epoch 135/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 0.5052 - val_accuracy: 0.7013 - val_loss: 0.5418\n",
            "Epoch 136/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.5406 - val_accuracy: 0.7013 - val_loss: 0.5414\n",
            "Epoch 137/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.5357 - val_accuracy: 0.7013 - val_loss: 0.5409\n",
            "Epoch 138/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.5274 - val_accuracy: 0.7013 - val_loss: 0.5405\n",
            "Epoch 139/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4980 - val_accuracy: 0.7013 - val_loss: 0.5401\n",
            "Epoch 140/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7649 - loss: 0.5176 - val_accuracy: 0.7013 - val_loss: 0.5397\n",
            "Epoch 141/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.5047 - val_accuracy: 0.7013 - val_loss: 0.5392\n",
            "Epoch 142/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7487 - loss: 0.5259 - val_accuracy: 0.7013 - val_loss: 0.5388\n",
            "Epoch 143/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.5329 - val_accuracy: 0.7078 - val_loss: 0.5385\n",
            "Epoch 144/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.5212 - val_accuracy: 0.7078 - val_loss: 0.5381\n",
            "Epoch 145/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.5344 - val_accuracy: 0.7078 - val_loss: 0.5377\n",
            "Epoch 146/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7671 - loss: 0.4930 - val_accuracy: 0.7078 - val_loss: 0.5373\n",
            "Epoch 147/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7714 - loss: 0.5127 - val_accuracy: 0.7078 - val_loss: 0.5369\n",
            "Epoch 148/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7490 - loss: 0.5134 - val_accuracy: 0.7143 - val_loss: 0.5366\n",
            "Epoch 149/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 0.5051 - val_accuracy: 0.7208 - val_loss: 0.5362\n",
            "Epoch 150/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.5274 - val_accuracy: 0.7208 - val_loss: 0.5359\n",
            "Epoch 151/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7643 - loss: 0.5099 - val_accuracy: 0.7208 - val_loss: 0.5355\n",
            "Epoch 152/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4828 - val_accuracy: 0.7208 - val_loss: 0.5352\n",
            "Epoch 153/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7579 - loss: 0.5131 - val_accuracy: 0.7208 - val_loss: 0.5348\n",
            "Epoch 154/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.4973 - val_accuracy: 0.7208 - val_loss: 0.5345\n",
            "Epoch 155/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7251 - loss: 0.5268 - val_accuracy: 0.7208 - val_loss: 0.5342\n",
            "Epoch 156/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7412 - loss: 0.5220 - val_accuracy: 0.7208 - val_loss: 0.5339\n",
            "Epoch 157/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7776 - loss: 0.5155 - val_accuracy: 0.7208 - val_loss: 0.5336\n",
            "Epoch 158/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.5132 - val_accuracy: 0.7208 - val_loss: 0.5333\n",
            "Epoch 159/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.5138 - val_accuracy: 0.7208 - val_loss: 0.5330\n",
            "Epoch 160/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.5051 - val_accuracy: 0.7208 - val_loss: 0.5327\n",
            "Epoch 161/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.5118 - val_accuracy: 0.7208 - val_loss: 0.5324\n",
            "Epoch 162/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7903 - loss: 0.4847 - val_accuracy: 0.7208 - val_loss: 0.5321\n",
            "Epoch 163/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7679 - loss: 0.4878 - val_accuracy: 0.7208 - val_loss: 0.5318\n",
            "Epoch 164/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7731 - loss: 0.5015 - val_accuracy: 0.7208 - val_loss: 0.5316\n",
            "Epoch 165/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.5184 - val_accuracy: 0.7208 - val_loss: 0.5313\n",
            "Epoch 166/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7355 - loss: 0.5327 - val_accuracy: 0.7208 - val_loss: 0.5310\n",
            "Epoch 167/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.5052 - val_accuracy: 0.7208 - val_loss: 0.5308\n",
            "Epoch 168/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7584 - loss: 0.5076 - val_accuracy: 0.7208 - val_loss: 0.5305\n",
            "Epoch 169/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.5187 - val_accuracy: 0.7208 - val_loss: 0.5302\n",
            "Epoch 170/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.5221 - val_accuracy: 0.7208 - val_loss: 0.5300\n",
            "Epoch 171/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.5192 - val_accuracy: 0.7208 - val_loss: 0.5298\n",
            "Epoch 172/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7664 - loss: 0.5057 - val_accuracy: 0.7208 - val_loss: 0.5295\n",
            "Epoch 173/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4863 - val_accuracy: 0.7208 - val_loss: 0.5293\n",
            "Epoch 174/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4896 - val_accuracy: 0.7208 - val_loss: 0.5291\n",
            "Epoch 175/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7437 - loss: 0.5187 - val_accuracy: 0.7208 - val_loss: 0.5289\n",
            "Epoch 176/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 0.5070 - val_accuracy: 0.7208 - val_loss: 0.5287\n",
            "Epoch 177/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.5064 - val_accuracy: 0.7208 - val_loss: 0.5284\n",
            "Epoch 178/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.4910 - val_accuracy: 0.7208 - val_loss: 0.5282\n",
            "Epoch 179/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 0.4831 - val_accuracy: 0.7273 - val_loss: 0.5280\n",
            "Epoch 180/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.5254 - val_accuracy: 0.7273 - val_loss: 0.5278\n",
            "Epoch 181/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4775 - val_accuracy: 0.7273 - val_loss: 0.5276\n",
            "Epoch 182/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7428 - loss: 0.5176 - val_accuracy: 0.7273 - val_loss: 0.5274\n",
            "Epoch 183/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.4965 - val_accuracy: 0.7273 - val_loss: 0.5272\n",
            "Epoch 184/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7798 - loss: 0.4842 - val_accuracy: 0.7273 - val_loss: 0.5270\n",
            "Epoch 185/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.4973 - val_accuracy: 0.7273 - val_loss: 0.5268\n",
            "Epoch 186/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.4761 - val_accuracy: 0.7273 - val_loss: 0.5266\n",
            "Epoch 187/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7665 - loss: 0.4833 - val_accuracy: 0.7273 - val_loss: 0.5265\n",
            "Epoch 188/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7451 - loss: 0.5085 - val_accuracy: 0.7273 - val_loss: 0.5263\n",
            "Epoch 189/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.4862 - val_accuracy: 0.7273 - val_loss: 0.5261\n",
            "Epoch 190/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.4957 - val_accuracy: 0.7273 - val_loss: 0.5259\n",
            "Epoch 191/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.5023 - val_accuracy: 0.7273 - val_loss: 0.5257\n",
            "Epoch 192/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4653 - val_accuracy: 0.7273 - val_loss: 0.5256\n",
            "Epoch 193/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.5011 - val_accuracy: 0.7273 - val_loss: 0.5254\n",
            "Epoch 194/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.5103 - val_accuracy: 0.7273 - val_loss: 0.5253\n",
            "Epoch 195/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7648 - loss: 0.4861 - val_accuracy: 0.7273 - val_loss: 0.5251\n",
            "Epoch 196/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.4940 - val_accuracy: 0.7273 - val_loss: 0.5249\n",
            "Epoch 197/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.4982 - val_accuracy: 0.7273 - val_loss: 0.5248\n",
            "Epoch 198/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4828 - val_accuracy: 0.7273 - val_loss: 0.5246\n",
            "Epoch 199/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7430 - loss: 0.4857 - val_accuracy: 0.7273 - val_loss: 0.5245\n",
            "Epoch 200/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7150 - loss: 0.5396 - val_accuracy: 0.7273 - val_loss: 0.5243\n",
            "Epoch 201/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7861 - loss: 0.4754 - val_accuracy: 0.7273 - val_loss: 0.5242\n",
            "Epoch 202/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.5223 - val_accuracy: 0.7273 - val_loss: 0.5240\n",
            "Epoch 203/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 0.4752 - val_accuracy: 0.7273 - val_loss: 0.5239\n",
            "Epoch 204/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4765 - val_accuracy: 0.7273 - val_loss: 0.5238\n",
            "Epoch 205/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7703 - loss: 0.4912 - val_accuracy: 0.7273 - val_loss: 0.5236\n",
            "Epoch 206/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.7273 - val_loss: 0.5235\n",
            "Epoch 207/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7397 - loss: 0.5189 - val_accuracy: 0.7273 - val_loss: 0.5234\n",
            "Epoch 208/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7748 - loss: 0.4909 - val_accuracy: 0.7338 - val_loss: 0.5233\n",
            "Epoch 209/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7576 - loss: 0.5032 - val_accuracy: 0.7338 - val_loss: 0.5231\n",
            "Epoch 210/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.4984 - val_accuracy: 0.7338 - val_loss: 0.5230\n",
            "Epoch 211/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.4930 - val_accuracy: 0.7338 - val_loss: 0.5229\n",
            "Epoch 212/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 0.4652 - val_accuracy: 0.7338 - val_loss: 0.5228\n",
            "Epoch 213/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.5477 - val_accuracy: 0.7338 - val_loss: 0.5227\n",
            "Epoch 214/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7537 - loss: 0.5127 - val_accuracy: 0.7273 - val_loss: 0.5226\n",
            "Epoch 215/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.4795 - val_accuracy: 0.7273 - val_loss: 0.5224\n",
            "Epoch 216/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.4939 - val_accuracy: 0.7273 - val_loss: 0.5223\n",
            "Epoch 217/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.5073 - val_accuracy: 0.7273 - val_loss: 0.5222\n",
            "Epoch 218/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4761 - val_accuracy: 0.7273 - val_loss: 0.5221\n",
            "Epoch 219/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.4726 - val_accuracy: 0.7273 - val_loss: 0.5220\n",
            "Epoch 220/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7723 - loss: 0.4814 - val_accuracy: 0.7273 - val_loss: 0.5219\n",
            "Epoch 221/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.4820 - val_accuracy: 0.7273 - val_loss: 0.5218\n",
            "Epoch 222/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.4812 - val_accuracy: 0.7273 - val_loss: 0.5217\n",
            "Epoch 223/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.4698 - val_accuracy: 0.7273 - val_loss: 0.5216\n",
            "Epoch 224/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7498 - loss: 0.4983 - val_accuracy: 0.7273 - val_loss: 0.5215\n",
            "Epoch 225/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.4837 - val_accuracy: 0.7273 - val_loss: 0.5214\n",
            "Epoch 226/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7724 - loss: 0.4853 - val_accuracy: 0.7273 - val_loss: 0.5213\n",
            "Epoch 227/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.5051 - val_accuracy: 0.7273 - val_loss: 0.5212\n",
            "Epoch 228/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4714 - val_accuracy: 0.7273 - val_loss: 0.5211\n",
            "Epoch 229/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.5126 - val_accuracy: 0.7273 - val_loss: 0.5210\n",
            "Epoch 230/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 0.4876 - val_accuracy: 0.7273 - val_loss: 0.5210\n",
            "Epoch 231/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.4668 - val_accuracy: 0.7338 - val_loss: 0.5209\n",
            "Epoch 232/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.4967 - val_accuracy: 0.7338 - val_loss: 0.5208\n",
            "Epoch 233/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7681 - loss: 0.4999 - val_accuracy: 0.7338 - val_loss: 0.5207\n",
            "Epoch 234/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4738 - val_accuracy: 0.7273 - val_loss: 0.5206\n",
            "Epoch 235/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8000 - loss: 0.4440 - val_accuracy: 0.7273 - val_loss: 0.5205\n",
            "Epoch 236/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.4915 - val_accuracy: 0.7273 - val_loss: 0.5205\n",
            "Epoch 237/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7411 - loss: 0.5072 - val_accuracy: 0.7273 - val_loss: 0.5204\n",
            "Epoch 238/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7690 - loss: 0.4691 - val_accuracy: 0.7273 - val_loss: 0.5203\n",
            "Epoch 239/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 0.4760 - val_accuracy: 0.7273 - val_loss: 0.5202\n",
            "Epoch 240/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.4755 - val_accuracy: 0.7273 - val_loss: 0.5202\n",
            "Epoch 241/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.4542 - val_accuracy: 0.7273 - val_loss: 0.5201\n",
            "Epoch 242/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7706 - loss: 0.5024 - val_accuracy: 0.7273 - val_loss: 0.5200\n",
            "Epoch 243/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7551 - loss: 0.4815 - val_accuracy: 0.7273 - val_loss: 0.5199\n",
            "Epoch 244/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7459 - loss: 0.5091 - val_accuracy: 0.7273 - val_loss: 0.5199\n",
            "Epoch 245/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 0.4775 - val_accuracy: 0.7273 - val_loss: 0.5198\n",
            "Epoch 246/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7535 - loss: 0.5122 - val_accuracy: 0.7273 - val_loss: 0.5197\n",
            "Epoch 247/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7643 - loss: 0.4889 - val_accuracy: 0.7273 - val_loss: 0.5197\n",
            "Epoch 248/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7860 - loss: 0.4875 - val_accuracy: 0.7273 - val_loss: 0.5196\n",
            "Epoch 249/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.4721 - val_accuracy: 0.7273 - val_loss: 0.5195\n",
            "Epoch 250/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7558 - loss: 0.4733 - val_accuracy: 0.7273 - val_loss: 0.5195\n",
            "Epoch 251/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7664 - loss: 0.4844 - val_accuracy: 0.7273 - val_loss: 0.5194\n",
            "Epoch 252/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.4840 - val_accuracy: 0.7273 - val_loss: 0.5193\n",
            "Epoch 253/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7585 - loss: 0.5019 - val_accuracy: 0.7273 - val_loss: 0.5193\n",
            "Epoch 254/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7599 - loss: 0.4850 - val_accuracy: 0.7273 - val_loss: 0.5192\n",
            "Epoch 255/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.4737 - val_accuracy: 0.7273 - val_loss: 0.5192\n",
            "Epoch 256/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7769 - loss: 0.4962 - val_accuracy: 0.7273 - val_loss: 0.5191\n",
            "Epoch 257/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7707 - loss: 0.4695 - val_accuracy: 0.7273 - val_loss: 0.5190\n",
            "Epoch 258/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.4910 - val_accuracy: 0.7273 - val_loss: 0.5190\n",
            "Epoch 259/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7602 - loss: 0.4970 - val_accuracy: 0.7273 - val_loss: 0.5189\n",
            "Epoch 260/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 0.4737 - val_accuracy: 0.7273 - val_loss: 0.5189\n",
            "Epoch 261/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.4463 - val_accuracy: 0.7273 - val_loss: 0.5188\n",
            "Epoch 262/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7516 - loss: 0.4815 - val_accuracy: 0.7273 - val_loss: 0.5188\n",
            "Epoch 263/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.4641 - val_accuracy: 0.7273 - val_loss: 0.5187\n",
            "Epoch 264/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7536 - loss: 0.4774 - val_accuracy: 0.7273 - val_loss: 0.5187\n",
            "Epoch 265/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.4717 - val_accuracy: 0.7273 - val_loss: 0.5186\n",
            "Epoch 266/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7700 - loss: 0.4848 - val_accuracy: 0.7273 - val_loss: 0.5186\n",
            "Epoch 267/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7523 - loss: 0.5136 - val_accuracy: 0.7273 - val_loss: 0.5185\n",
            "Epoch 268/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4911 - val_accuracy: 0.7273 - val_loss: 0.5185\n",
            "Epoch 269/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 0.4971 - val_accuracy: 0.7273 - val_loss: 0.5184\n",
            "Epoch 270/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.5175 - val_accuracy: 0.7273 - val_loss: 0.5184\n",
            "Epoch 271/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.4800 - val_accuracy: 0.7273 - val_loss: 0.5183\n",
            "Epoch 272/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.4820 - val_accuracy: 0.7273 - val_loss: 0.5183\n",
            "Epoch 273/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.5008 - val_accuracy: 0.7273 - val_loss: 0.5182\n",
            "Epoch 274/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.4541 - val_accuracy: 0.7273 - val_loss: 0.5182\n",
            "Epoch 275/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4680 - val_accuracy: 0.7273 - val_loss: 0.5181\n",
            "Epoch 276/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 0.4623 - val_accuracy: 0.7273 - val_loss: 0.5181\n",
            "Epoch 277/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.4974 - val_accuracy: 0.7273 - val_loss: 0.5181\n",
            "Epoch 278/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.4688 - val_accuracy: 0.7338 - val_loss: 0.5180\n",
            "Epoch 279/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.4767 - val_accuracy: 0.7338 - val_loss: 0.5180\n",
            "Epoch 280/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7765 - loss: 0.4750 - val_accuracy: 0.7338 - val_loss: 0.5179\n",
            "Epoch 281/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.4676 - val_accuracy: 0.7338 - val_loss: 0.5179\n",
            "Epoch 282/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7691 - loss: 0.4934 - val_accuracy: 0.7338 - val_loss: 0.5178\n",
            "Epoch 283/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7546 - loss: 0.4968 - val_accuracy: 0.7338 - val_loss: 0.5178\n",
            "Epoch 284/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7683 - loss: 0.4766 - val_accuracy: 0.7273 - val_loss: 0.5178\n",
            "Epoch 285/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4662 - val_accuracy: 0.7273 - val_loss: 0.5177\n",
            "Epoch 286/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.5301 - val_accuracy: 0.7338 - val_loss: 0.5177\n",
            "Epoch 287/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.4780 - val_accuracy: 0.7338 - val_loss: 0.5176\n",
            "Epoch 288/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7970 - loss: 0.4689 - val_accuracy: 0.7338 - val_loss: 0.5176\n",
            "Epoch 289/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7557 - loss: 0.4735 - val_accuracy: 0.7338 - val_loss: 0.5176\n",
            "Epoch 290/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7683 - loss: 0.4897 - val_accuracy: 0.7338 - val_loss: 0.5175\n",
            "Epoch 291/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7222 - loss: 0.5110 - val_accuracy: 0.7338 - val_loss: 0.5175\n",
            "Epoch 292/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7798 - loss: 0.4614 - val_accuracy: 0.7338 - val_loss: 0.5175\n",
            "Epoch 293/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.4813 - val_accuracy: 0.7338 - val_loss: 0.5174\n",
            "Epoch 294/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7948 - loss: 0.4643 - val_accuracy: 0.7273 - val_loss: 0.5174\n",
            "Epoch 295/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 0.4570 - val_accuracy: 0.7273 - val_loss: 0.5174\n",
            "Epoch 296/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7622 - loss: 0.4818 - val_accuracy: 0.7273 - val_loss: 0.5173\n",
            "Epoch 297/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7513 - loss: 0.5099 - val_accuracy: 0.7273 - val_loss: 0.5173\n",
            "Epoch 298/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.4787 - val_accuracy: 0.7273 - val_loss: 0.5173\n",
            "Epoch 299/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4663 - val_accuracy: 0.7273 - val_loss: 0.5172\n",
            "Epoch 300/300\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.4673 - val_accuracy: 0.7273 - val_loss: 0.5172\n",
            "Training Accuracy: 0.7704\n",
            "Testing Accuracy: 0.7273\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.83      0.80       100\n",
            "           1       0.63      0.54      0.58        54\n",
            "\n",
            "    accuracy                           0.73       154\n",
            "   macro avg       0.70      0.68      0.69       154\n",
            "weighted avg       0.72      0.73      0.72       154\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e9e1c4711c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "Model Prediction: Non-Diabetic (Probability: 0.4616)\n"
          ]
        }
      ],
      "source": [
        "# Diabetes Diagnosis using Artificial Neural Networks (ANN)\n",
        "\n",
        "## Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Loading and Displaying Data\n",
        "# Load the dataset\n",
        "file_path = \"/content/diabetes.csv\"  # Ensure the file is in the same directory\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display first few rows\n",
        "print(df.head())\n",
        "\n",
        "## Preprocessing Data\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=[\"Outcome\"])\n",
        "y = df[\"Outcome\"]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Check dataset shapes\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n",
        "\n",
        "## Building the ANN Model\n",
        "# Define the ANN model\n",
        "model = Sequential([\n",
        "    Dense(12, activation='swish', input_shape=(8,)),  # Hidden Layer 1\n",
        "    Dense(25, activation='swish'),                    # Hidden Layer 2\n",
        "    Dense(15, activation='swish'),                    # Hidden Layer 3\n",
        "    Dense(1, activation='sigmoid')                    # Output Layer (binary classification)\n",
        "])\n",
        "\n",
        "# Compile the model with Adagrad optimizer and accuracy metric\n",
        "model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Save the trained model in the new Keras format\n",
        "model.save(\"diabetes_model.keras\")  # Updated format\n",
        "\n",
        "## Evaluating Model Performance\n",
        "# Evaluate model performance\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Precision, Recall, F1-score\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "## Deploying the Model\n",
        "# Load the saved model in the new format\n",
        "loaded_model = keras.models.load_model(\"diabetes_model.keras\")  # ✅ Corrected\n",
        "\n",
        "# Test with a new sample (random test case from dataset)\n",
        "sample_input = X_test[0].reshape(1, -1)\n",
        "prediction = loaded_model.predict(sample_input)[0][0]\n",
        "predicted_class = \"Diabetic\" if prediction > 0.5 else \"Non-Diabetic\"\n",
        "\n",
        "print(f\"Model Prediction: {predicted_class} (Probability: {prediction:.4f})\")\n"
      ]
    }
  ]
}